{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "## How to use:\n",
    "### If the test dataset is in the same format as the train dataset provided, \n",
    "Please change the file path under section III\n",
    "### Else if the dataset is similar to the input and output of the model, of the following:\n",
    "Input:<br>\n",
    "[demand on T-1248, demand on T-1247 ... demand on T, latitude, longitude] **1251** columns <br>\n",
    "Output: <br>\n",
    "[demand on T+1,... demand on T+5] **5** columns <br>\n",
    "<br>\n",
    "Please make them into float and pass directly into the prediction model under section IV\n",
    "### Else\n",
    "Please try to process the test set into either format mentioned above. I apologize for any inconvenience\n",
    "## Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### If missing any library, please uncomment the repective line below and pip install\n",
    "#!pip install tensorflow --upgrade\n",
    "#!pip install h5py\n",
    "#!pip install numpy --upgrade\n",
    "#!pip install pandas\n",
    "#!pip install dask --upgrade\n",
    "\n",
    "## Taken from https://pypi.org/project/pygeohash/\n",
    "## Using this instead of the python-geohash by hiwi due to better documentation\n",
    "\n",
    "#!pip install pygeohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pygeohash as pgh\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "tqdm_notebook.pandas()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters,_,_,_ = pickle.load(open(\"training_parameters.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "parameters,_,_ = pickle.load(open(\"training_parameters-30 rounds.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Load Test Data and preparation\n",
    "Here I use a sample 10% sample test set for debugging and sanity check.\n",
    "<br><br>\n",
    "### Please replace the file path to actual test.csv 's path\n",
    "_**The test set should be in the same format as the training data, i.e 4 columns of: [geohash6 , day , timestamp , demand]**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"10%test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing to match the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting timestamp and day to a single number\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650ad6692f774df0b6580dfb74cecd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting to each row to record 13 days prior data as well as from T to T+5, latitude and longitude\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bd4d8aa3564781bf7d74047658249c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def string_to_time (string):\n",
    "    x = string.split(\":\")\n",
    "    timing = int(x[0]) * 60 + int(x[1])\n",
    "    return timing/15\n",
    "print(\"Converting timestamp and day to a single number\")\n",
    "df['time_stamp'] = df['timestamp'].progress_apply(string_to_time)\n",
    "df['time_stamp'] = df['time_stamp'] + (df['day'] - 1)*96\n",
    "\n",
    "de = df.groupby(['geohash6']).count()\n",
    "hash_list = de.index.values\n",
    "\n",
    "df = pd.pivot_table(df, values='demand', index=['time_stamp'],columns=['geohash6'])\n",
    "df = df.fillna(0)\n",
    "\n",
    "X = pd.DataFrame({\"index\":list(np.core.defchararray.add(\"T-\",np.arange(1248,0,-1).astype(\"str\")))+\\\n",
    "                       [\"T\",\"lat\",\"lon\"]})\n",
    "Y = pd.DataFrame({\"index\":[\"T+1\",\"T+2\",\"T+3\",\"T+4\",\"T+5\"]})\n",
    "\n",
    "k=0\n",
    "print(\"Converting to each row to record 13 days prior data as well as from T to T+5, latitude and longitude\")\n",
    "for geohash in tqdm_notebook(hash_list):\n",
    "    for i in range(1248,df.shape[0]-5):\n",
    "        if df[geohash].values[i] > 0:\n",
    "            try:\n",
    "                k+=1\n",
    "                X[str(k)] = list(df[geohash].values[i-1248:i+1])+[pgh.decode(geohash)[0],pgh.decode(geohash)[1]]\n",
    "                Y[str(k)] = list(df[geohash].values[i+1:i+6])\n",
    "            except:\n",
    "                k+=1\n",
    "                print(df[geohash].values[i])\n",
    "                print(list(df[geohash].values[i-1248:i+6])+[geohash])\n",
    "\n",
    "X=np.array(X.T.drop(['index'])).astype(\"float\")\n",
    "Y=np.array(Y.T.drop(['index'])).astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    '''\n",
    "    This function obtain coefficient of various parameters and use them to predict a final cost(Z3)\n",
    "    This process consists of  a linear function of X @ W1 + b1, @ being matrix multiplication,\n",
    "        followed by a retilinear activation function \n",
    "    '''\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(X,W1), b1)                      \n",
    "    A1 = tf.nn.relu(Z1)  \n",
    "    Z2 = tf.add(tf.matmul(A1,W2), b2)     \n",
    "    A2 = tf.nn.relu(Z2)    \n",
    "    Z3 = tf.add(tf.matmul(A2,W3), b3)  \n",
    "\n",
    "    return Z3\n",
    "\n",
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    try:\n",
    "        x = tf.placeholder(\"float\", [X.shape[0],X.shape[1]])\n",
    "    except:\n",
    "        x = tf.placeholder(\"float\", [1,X.shape[0]])\n",
    "    z3 = forward_propagation(x, params)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(z3, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the above functions to predict the values of T+1 to T+5 for each row<br> by using 13 days (1248 time stamps) of demand data, demand data at time = T, latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12361688, 0.12361688, 0.12361688, 0.12361688, 0.12361688],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict(X, parameters)\n",
    "prediction[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = Y\n",
    "actual[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Results\n",
    "#### Output the mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error is  0.015390041585956171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-43.62715449239896"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = mean_squared_error(actual,prediction)\n",
    "r = r2_score(actual,prediction)\n",
    "print(\"The mean squared error is \",results)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error is  0.0010957312489462156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.1923454087188343"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = mean_squared_error(actual,prediction)\n",
    "r = r2_score(actual,prediction)\n",
    "print(\"The mean squared error is \",results)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00891849, 0.00766036, 0.00651336, 0.00614237, 0.00655985],\n",
       "       [0.01737385, 0.01414197, 0.01108822, 0.00900204, 0.00809074],\n",
       "       [0.00643334, 0.00576075, 0.00516869, 0.00528677, 0.00607155],\n",
       "       ...,\n",
       "       [0.00578769, 0.00509157, 0.00446879, 0.00457932, 0.00538735],\n",
       "       [0.01271663, 0.01038673, 0.00818622, 0.00687822, 0.00658854],\n",
       "       [0.01935568, 0.01549025, 0.01182064, 0.00920088, 0.00790395]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.5075363 , 36.80343662, 35.95972593, 29.78476868, 32.23377708])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([956.6307 , 425.64618, 393.32312, 412.86932, 461.53748],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
