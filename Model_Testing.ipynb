{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "## How to use:\n",
    "### If the test dataset is in the same format as the train dataset provided, \n",
    "Please change the file path under section III\n",
    "### Else if the dataset is similar to the input and output of the model, of the following:\n",
    "Input:<br>\n",
    "[demand on T-1248, demand on T-1247 ... demand on T, latitude, longitude] **1251** columns <br>\n",
    "Output: <br>\n",
    "[demand on T+1,... demand on T+5] **5** columns <br>\n",
    "<br>\n",
    "Please make them into float and pass directly into the prediction model under section IV\n",
    "### Else\n",
    "Please try to process the test set into either format mentioned above. I apologize for any inconvenience\n",
    "## Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### If missing any library, please uncomment the repective line below and pip install\n",
    "#!pip install tensorflow --upgrade\n",
    "#!pip install h5py\n",
    "#!pip install numpy --upgrade\n",
    "#!pip install pandas\n",
    "#!pip install dask --upgrade\n",
    "\n",
    "## Taken from https://pypi.org/project/pygeohash/\n",
    "## Using this instead of the python-geohash by hiwi due to better documentation\n",
    "\n",
    "#!pip install pygeohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pygeohash as pgh\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "tqdm_notebook.pandas()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters,train_acc,dev_acc,train,k = pickle.load(open(\"training_parameters.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Load Test Data and preparation\n",
    "Here I use a sample 10% sample test set for debugging and sanity check.\n",
    "<br><br>\n",
    "### Please replace the file path to actual test.csv 's path\n",
    "_**The test set should be in the same format as the training data, i.e 4 columns of: [geohash6 , day , timestamp , demand]**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1%test_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing to match the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting timestamp and day to a single number\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98d03b790c642368662eff6476e915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting to each row to record 13 days prior data as well as from T to T+5, latitude and longitude\n",
      "This will take a while\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfa6c6818394281b8f63221c5142cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def string_to_time (string):\n",
    "    x = string.split(\":\")\n",
    "    timing = int(x[0]) * 60 + int(x[1])\n",
    "    return timing/15\n",
    "print(\"Converting timestamp and day to a single number\")\n",
    "df['time_stamp'] = df['timestamp'].progress_apply(string_to_time)\n",
    "df['time_stamp'] = df['time_stamp'] + (df['day'] - 1)*96\n",
    "\n",
    "de = df.groupby(['geohash6']).count()\n",
    "hash_list = de.index.values\n",
    "\n",
    "df = pd.pivot_table(df, values='demand', index=['time_stamp'],columns=['geohash6'])\n",
    "df = df.fillna(0)\n",
    "\n",
    "X = pd.DataFrame({\"index\":list(np.core.defchararray.add(\"T-\",np.arange(1248,0,-1).astype(\"str\")))+\\\n",
    "                       [\"T\",\"lat\",\"lon\"]})\n",
    "Y = pd.DataFrame({\"index\":[\"T+1\",\"T+2\",\"T+3\",\"T+4\",\"T+5\"]})\n",
    "\n",
    "k=0\n",
    "print(\"Converting to each row to record 13 days prior data as well as from T to T+5, latitude and longitude\\nThis will take a while\")\n",
    "for geohash in tqdm_notebook(hash_list):\n",
    "    for i in range(1248,df.shape[0]-5):\n",
    "        if df[geohash].values[i] > 0:\n",
    "            try:\n",
    "                k+=1\n",
    "                X[str(k)] = list(df[geohash].values[i-1248:i+1])+[pgh.decode(geohash)[0],pgh.decode(geohash)[1]]\n",
    "                Y[str(k)] = list(df[geohash].values[i+1:i+6])\n",
    "            except:\n",
    "                k+=1\n",
    "                print(df[geohash].values[i])\n",
    "                print(list(df[geohash].values[i-1248:i+6])+[geohash])\n",
    "\n",
    "X=np.array(X.T.drop(['index'])).astype(\"float\")\n",
    "Y=np.array(Y.T.drop(['index'])).astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    '''\n",
    "    This function obtain coefficient of various parameters and use them to predict a final cost(Z3)\n",
    "    This process consists of  a linear function of X @ W1 + b1, @ being matrix multiplication,\n",
    "        followed by a retilinear activation function \n",
    "    '''\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(X,W1), b1)                      \n",
    "    A1 = tf.nn.relu(Z1)  \n",
    "    Z2 = tf.add(tf.matmul(A1,W2), b2)     \n",
    "    A2 = tf.nn.relu(Z2)    \n",
    "    Z3 = tf.add(tf.matmul(A2,W3), b3)  \n",
    "\n",
    "    return Z3\n",
    "\n",
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    try:\n",
    "        x = tf.placeholder(\"float\", [X.shape[0],X.shape[1]])\n",
    "    except:\n",
    "        x = tf.placeholder(\"float\", [1,X.shape[0]])\n",
    "    z3 = forward_propagation(x, params)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(z3, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the above functions to predict the values of T+1 to T+5 for each row<br> by using 13 days (1248 time stamps) of demand data, demand data at time = T, latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00571937, 0.00571937, 0.00571937, 0.00571937, 0.00571937],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict(X, parameters)\n",
    "prediction[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = Y\n",
    "actual[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Results\n",
    "#### Output the mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error is  9.367622942142474e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.767429778114891"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = mean_squared_error(actual,prediction)\n",
    "r = r2_score(actual,prediction)\n",
    "print(\"The mean squared error is \",results)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00571937, 0.00571937, 0.00571937, 0.00571937, 0.00571937],\n",
       "       [0.00571937, 0.00571937, 0.00571937, 0.00571937, 0.00571937],\n",
       "       [0.00571937, 0.00571937, 0.00571937, 0.00571937, 0.00571937],\n",
       "       ...,\n",
       "       [0.00571937, 0.00571937, 0.00571937, 0.00571937, 0.00571937],\n",
       "       [0.00571937, 0.00571937, 0.00571937, 0.00571937, 0.00571937],\n",
       "       [0.00571937, 0.00571937, 0.00571937, 0.00571937, 0.00571937]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59979344, 0.        , 0.        , 0.41752594, 0.20360051])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
